{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, DS-поток\n",
    "## Домашнее задание 2\n",
    "\n",
    "**Правила:**\n",
    "\n",
    "* Дедлайн **28 февраля 10:00**. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Выполненную работу нужно отправить на почту ` mipt.stats@yandex.ru`, указав тему письма `\"[ml] Фамилия Имя - задание 2\"`. Квадратные скобки обязательны. Если письмо дошло, придет ответ от автоответчика.\n",
    "* Прислать нужно ноутбук и его pdf-версию (без архивов). Названия файлов должны быть такими: `2.N.ipynb` и `2.N.pdf`, где `N` - ваш номер из таблицы с оценками.\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качествие основы, ничего не удаляя из него.\n",
    "* Никакой код из данного задания при проверке запускаться не будет.\n",
    "\n",
    "**Баллы за задание:**\n",
    "\n",
    "* Задача 1 -  5 баллов\n",
    "* Задача 2 -  15 баллов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jIpdJCymYp4"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as sps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "sns.set(font_scale=1.4)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ynfmb3CDdFqk"
   },
   "source": [
    "### Задача 1\n",
    "\n",
    "Рассмотрим метод *логистической регрессии*. Пусть $x_i \\in \\mathbb{R}^d, Y_i \\sim Bern(\\mu_\\theta(x_i))$. \n",
    "\n",
    "Мы предполагаем, что $\\mu_\\theta(x_i) = P_\\theta(Y_i = 1)  = \\sigma(x_i^T\\theta)= \\frac{e^{x_i^T\\theta}}{1 + e^{x_i^T\\theta}}$.\n",
    "\n",
    "Регуляризацию в методе логистической регрессии можно задать с помощью введения априорного распределения на $\\theta$. Будем считать, что априорное распределения $\\mathcal{N}(0, \\alpha^{-1}I_d)$. В данном случае распределения не являются сопряженными, поэтому простым путем найти апостериорное распределение не получится. Однако, можно найти моду этого распределения. Выпишите соответствующую задачу оптимизации.\n",
    "\n",
    "Для данной задачи:\n",
    "1. Получите формулу градиентного спуска.\n",
    "2. Получите формулу метода IRLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6MhJsMVmGG_"
   },
   "source": [
    "### Задача 2\n",
    "\n",
    "**1.**\n",
    "\n",
    "Реализуйте логистическую регрессию с регуляризацией для трех вариантов поиска оценки параметров:\n",
    "* обычный градиентный спуск;\n",
    "* стохастический mini-batch градиентный спуск, размер батча 5-10;\n",
    "* IRLS.\n",
    "\n",
    "Для измерения времени работы **каждого** шага используйте \n",
    "\n",
    "`from time import time`\n",
    "\n",
    "*Замечание.* Для чистоты эксперимента время шага внутри цикла `for` нужно замерять от конца предыдущего шага до конца текущего, а не от начала текущего шага."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4xxxebKnQLm"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    '''\n",
    "    Модель логистической регрессии. Имеет следующие гиперпараметры:\n",
    "    \n",
    "    * alpha: параметр регуляризации. \n",
    "             Если равно 0, то регуляризация не происходит.\n",
    "    * lr: константа, на которую домножаем градиент при обучении\n",
    "    * eps: ограничение на норму невязки в случае\n",
    "           если используется критерий criterion='eps'\n",
    "    * max_iter: ограничение на кол-во итераций в случае \n",
    "                если используется критерий criterion='max_iter'\n",
    "    * method: если равно 'gd', то используется обычный градиентный спуск,\n",
    "              если равно 'sgd', то используется стохастический \n",
    "                    градиентный спуск,\n",
    "              если равно 'irls', то используется метод IRLS.\n",
    "    * criterion: если равно 'eps', то используем ограничение \n",
    "                    на норму невязки,\n",
    "                 если равно 'max_iter', то используем ограничение \n",
    "                    на количество итераций\n",
    "    * fit_intercept: указывает, следует ли добавить константу в признаки\n",
    "    * save_history: указывает, следует ли сохранять историю обучения\n",
    "    '''\n",
    "    \n",
    "\n",
    "    def __init__(self, alpha=0, lr=0.5, eps=1e-3, max_iter=1e5, \n",
    "                 method='gd', criterion='max_iter', \n",
    "                 fit_intercept=True, save_history=True):\n",
    "        ''' Создает модель и инициализирует параметры '''\n",
    "\n",
    "        assert criterion in ['max_iter', 'eps'], 'выбран неправильный критерий остановки'\n",
    "        assert method in ['gd', 'sgd', 'irls'], 'выбран неправильный метод'\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.lr = lr\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.criterion = criterion\n",
    "        self.method = method\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.save_history = save_history\n",
    "        self.history = []  # для хранения истории обучения\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def _sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    \n",
    "    def _compute_loss(self, X, y):\n",
    "        return <...>\n",
    "\n",
    "    \n",
    "    def _add_intercept(self, X):\n",
    "        ''' \n",
    "        Добавляем свободный коэфициент к нашей модели. \n",
    "        Это происходит путем добавления вектора из 1 к исходной матрице.\n",
    "        '''\n",
    "        \n",
    "        X_copy = np.full((X.shape[0], X.shape[1] + 1), fill_value=1)\n",
    "        X_copy[:, :-1] = X\n",
    "\n",
    "        return X_copy\n",
    "\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ''' \n",
    "        Обучает модель логистической регресии с помощью выбранного метода,\n",
    "        пока не выполнится критерий остновки self.criterion.\n",
    "        Также, в случае self.save_history=True, добавляет в self.history \n",
    "        текущее значение оптимизируемого функционала \n",
    "        и время обновления коэффициентов. \n",
    "        '''\n",
    "        \n",
    "        assert X.shape[0] == Y.shape[0]\n",
    "\n",
    "        if self.fit_intercept:  # добавляем свободный коэфициент\n",
    "            X_copy = self._add_intercept(X)\n",
    "        else:\n",
    "            X_copy = X.copy()\n",
    "\n",
    "        <...>\n",
    "        \n",
    "        self.coef_ = <...>  # коэффициенты модели\n",
    "        self.intercept_ = <...>  # свободный коэффициент\n",
    "        self.n_iter_ = <...>  # произведенное число итераций\n",
    "        \n",
    "        return self\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Применяет обученную модель к данным \n",
    "        и возвращает точечное предсказание (оценку класса).\n",
    "        '''\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            X_copy = self._add_intercept(X)\n",
    "        else:\n",
    "            X_copy = X.copy()\n",
    "\n",
    "        assert X_copy.shape[1] == self.weights.shape[0]\n",
    "\n",
    "        <...>\n",
    "        \n",
    "        return predictions  # shape = (n_test,)\n",
    "\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        ''' Применяет обученную модель к данным\n",
    "        и возвращает предсказание вероятности классов 0 и 1. '''\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            X_copy = self._add_intercept(X)\n",
    "        else:\n",
    "            X_copy = X.copy()\n",
    "\n",
    "        assert X_copy.shape[1] == self.weights.shape[0]\n",
    "\n",
    "        <...>\n",
    "        \n",
    "        return prob_predictions  # shape = (n_test, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим игрушечный датасет на 30 признаков `load_breast_cancer` из библиотеки `sklearn`. Это относительно простой для двуклассовой классификации датасет по диагностике рака молочной железы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HHPTpzcWhv_W"
   },
   "source": [
    "Ради интереса можно прочитать описание признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "uUMbGPj-Fgfi",
    "outputId": "9b6b8f4b-d90a-42d7-d6d7-880c5853a33c"
   },
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "dataset['DESCR'].split('\\n')[11:31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JgaXPncW-Gab"
   },
   "source": [
    "Разделим нашу выборку на обучающую и тестовую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WEn6HImRc8zJ",
    "outputId": "9c25a5a2-4ea6-4e33-c9be-b780470fbbbb"
   },
   "outputs": [],
   "source": [
    "X, Y = dataset['data'], dataset['target']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test \\\n",
    "        = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8jzwZUCPB_l"
   },
   "source": [
    "При использовании регуляризации данные необходимо нормализовать. Воспользуемся для этого классом `StandardScaler` из библиотеки `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNAqhHbZPBvb"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v6b6xWybP8Mf"
   },
   "source": [
    "**2.** Теперь обучите три модели логистические регрессии без регуляризации с помощью методов\n",
    "* обычный градиентный спуск;\n",
    "* стохастический mini-batch градиентный спуск;\n",
    "* IRLS\n",
    "\n",
    "Постройте график, на котором нанесите три кривые обучения, каждая из которых отображает зависимость оптимизируемого функционала от номера итерации метода. Функционал должен быть одинаковый для всех моделей, то есть без минусов. Нариуйте также график зависимости этого функционала от времени работы метода.\n",
    "\n",
    "Для чистоты эксперимента желательно не запускать в момент обучения другие задачи и провести обучение несколько раз, усреднив результаты.\n",
    "\n",
    "*Напоминание:* все графики должны быть информативны, с подписанными осями и т.д.\n",
    "\n",
    "Сделайте выводы. Что будет, если при обучении на очень большой по количеству элементов датасете?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yZEZS1tnv1q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Se6YDPAgABHh"
   },
   "source": [
    "**3.** Сравните два реализованных критерия остановки по количеству проведенных итераций: евклидова норма разности текущего и нового векторов весов стала меньше, чем 1e-4 и ограничение на число итераций (например, 10000). Используйте градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQ1mGS2In4zN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mE0rZ7vPCH_S"
   },
   "source": [
    "**4.** Рассмотрите как влияет размер шага (`learning rate`) на качество модели. Обучите каждую модель одинаковое число итераций (например, 10000), а затем посчитайте качество. Воспользуйтесь ограничением на число итераций в качестве критерия остановки, так как для больших `learning rate` у вас может не сойтись модель. Используйте стохастический градиентный спуск. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UL0NzUTDbuxW"
   },
   "outputs": [],
   "source": [
    "lrs = [0.01, 0.1, 0.2, 0.3, 0.5, 0.7, 1, 2, 5, 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7PmOrPczPamX"
   },
   "source": [
    "Постройте кривые обучения для различных `learning rate`. Не обязательно рассматривать все `learning rate` из предыдущего задания, так как их слишком много, и график будет нагроможден. Возьмите около половины из них. Какой `learning rate` лучше выбрать? Чем плохи маленькие и большие `learning rate`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RTTmq9SAoBJQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UQy0zIrcClfm"
   },
   "source": [
    "**5.** Рассмотрите несколько моделей, в которых установите не менее 5-ти различных коэффициентов регуляризации, а также модель без регуляризатора. Сравните, влияет ли наличие регуляризации на скорость сходимости и качество, сделайте выводы. Под качеством подразумевается значение метрики, рассмотренных на семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Выберите произвольные два признака, в пространстве которых визуализируйте предсказания вероятностей класса 1 для модели, которая показала наилучшее качество на предыдущем шаге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LogisticRegresion1_no_solutions_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
