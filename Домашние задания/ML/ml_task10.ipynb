{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение, DS-поток\n",
    "## Домашнее задание 10\n",
    "\n",
    "**Правила:**\n",
    "\n",
    "* Дедлайн **22 мая 23:59**. После дедлайна работы не принимаются кроме случаев наличия уважительной причины.\n",
    "* Выполненную работу нужно отправить на почту ` mipt.stats@yandex.ru`, указав тему письма `\"[ml] Фамилия Имя - задание 10\"`. Квадратные скобки обязательны. Если письмо дошло, придет ответ от автоответчика.\n",
    "* Прислать нужно ноутбук, его pdf-версию (без архивов) и ссылку на google диск с весами лучшей модели. Названия файлов должны быть такими: `10.N.ipynb` и `10.N.pdf`, где `N` - ваш номер из таблицы с оценками.\n",
    "* Теоретические задачи необходимо оформить в техе/markdown или же прислать фотку в правильной ориентации рукописного решения, **где все четко видно**.\n",
    "* Решения, размещенные на каких-либо интернет-ресурсах не принимаются. Кроме того, публикация решения в открытом доступе может быть приравнена к предоставлении возможности списать.\n",
    "* Для выполнения задания используйте этот ноутбук в качествие основы, ничего не удаляя из него.\n",
    "\n",
    "**Баллы за задание:**\n",
    "\n",
    "* Часть 1 – 20 баллов\n",
    "* Часть 2 – 5 баллов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xMi_1QOK3vQQ"
   },
   "source": [
    "## Часть 1: Сверточные сети\n",
    "\n",
    "В этой домашней работе вам предстоит построить сверточную сеть для классификации картинок из датасета [**\"Best Artworks Of All Time\"**](https://www.kaggle.com/ikarus777/best-artworks-of-all-time). По изображению картины нужно предсказать автора (художника), написавшего ее.\n",
    "\n",
    "![](https://sun9-51.userapi.com/c858136/v858136162/1c0b61/GwA18z9fPIg.jpg)\n",
    "\n",
    "**Пожалуйста, прочитайте то, что написано ниже, там изложены требования к вашей работе и полезные советы!**\n",
    "\n",
    "Цель задания – построить нейросеть, чтобы достичь максимально возможного accuracy. В конце задания вы должны будете предоставить отчет о проделанной работе.\n",
    "\n",
    "**Оценивание вашей работы:**\n",
    "\n",
    "В сумме за домашнюю работу можно получить $25$ баллов.\n",
    "\n",
    "* +$3$ балла за работу за предоставление детального отчета (требования к нему изложены ниже).\n",
    "* +$3$ балла за построение нейросети, которая достигает значения Accuracy не менее 20% на тестовом датасете.\n",
    "* +$2$ балла за каждый следующий пройденный порог.\n",
    "    * 25% Accuracy\n",
    "    * 30% Accuracy\n",
    "    * 32.5% Accuracy\n",
    "    * 35% Accuracy\n",
    "    * 37.5% Accuracy\n",
    "    * 40% Accuracy\n",
    "    \n",
    "* +$2$ балла за выполнение \"задания на ваше знание статистики\". Вы можете найти его в конце всех советов и требований\n",
    "\n",
    "* +$5$ баллов за выполнение второй части задания (Transfer Learning)\n",
    "\n",
    "**Требование к работе:**\n",
    "\n",
    "* В этой части задания **запрещено** использовать предобученные нейросети. Для этого есть вторая часть домашней работы и она оценивается отдельно!\n",
    "\n",
    "* **Запрещено** использовать тестовые данные за исключением вычисления финальной оценки качества.\n",
    "\n",
    "* Сохраните веса лучшей модели с помощью `torch.save` ([инструкция](https://pytorch.org/tutorials/beginner/saving_loading_models.html)) и пришлите ссылку на файл с весами на google диске. Так мы сможем проверить выполнение предыдущего пункта. **Работы без присланных весов не будут засчитаны.**\n",
    "\n",
    "    Пример сохранения и загрузки весов:\n",
    "    \n",
    "    ```\n",
    "    # Save:\n",
    "    torch.save(model, PATH)\n",
    "\n",
    "    # Load:\n",
    "    model = torch.load(PATH)\n",
    "    model.eval()\n",
    "\n",
    "    ```\n",
    "\n",
    "    Более подробную инструкцию можно найти по [ссылке](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
    "\n",
    "**Требования к отчёту:**\n",
    "\n",
    "* Опишите свои эксперименты: с чего вы начали, что попробовали улучшить и почему, заработало это или нет, какие вы сделали из этого выводы.\n",
    "\n",
    "* Опишите вашу лучшую архитектуру, методы обучения и интересные моменты.\n",
    "\n",
    "\n",
    "### Советы:\n",
    "\n",
    "#### Архитектура нейросети:\n",
    "* Это задание может быть решено последовательностью сверток, пулингов, батчнорма и активаций, но не стоит останавливаться на этом.\n",
    "* Можно рассмотреть такие архитектуры как [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions](https://arxiv.org/abs/1608.06993). Однако вам нужно будет реализовать их самостоятельно.\n",
    "* Попробуйте сначала построить простую нейросеть, чтобы понять как с ними работать, перед тем как использовать resnet-152.\n",
    "* Также можно попробовать разные активации: `tanh`, `leaky relu` и другие.\n",
    "\n",
    "#### Переобучение:\n",
    "Если ваша нейросеть переобучается (лосс на тесте падает, а на валидации растет), вот некоторые методы, как с этим бороться:\n",
    "* Попробуйте добавить Dropout. Не бойтесь удалять много данных, но всегда проверяйте, что это не испортило вам качество.\n",
    "* Добавьте L2 регуляризацию весов (начните с небольшого значения). Регуляризация контролируется параметром `weight_decay` оптимизатора.\n",
    "* Попробуйте уменьшать `learning rate` с течением времени. В этом поможет `torch.optim.lr_scheduler`.\n",
    "* Уменьшите число нейронов в сети.\n",
    "* [Прерывайте обучение](https://github.com/Bjarten/early-stopping-pytorch), если сеть начала переобучаться.\n",
    "\n",
    "#### Процесс обучения:\n",
    "* Воспользуйтесь GPU google colab или любой другой GPU, которая у вас есть. \n",
    "* Для сокращения вычислительной сложности можно поэксперементировать с параметром `stride`. \n",
    "* Эксперементируйте с оптимизаторами: `rmsprop`, `nesterov_momentum`, `adam`, `adagrad` и далее. В этом вам поможет  `torch.optim`.\n",
    "* Помните, что некоторым нейросетям требуется $10$ эпох, чтобы сойтись, а некоторым – $500$. Большие нейросети дольше обучаются.\n",
    "* Если вы достигли какого-то порога на валидации лучше подождать примерно 10 эпох перед тем как останавливать обучение.\n",
    "\n",
    "#### Аугментация данных:\n",
    "* Вы можете использовать любые библиотеки для аугментации данных, например: [torchvision.transforms](https://pytorch.org/docs/stable/torchvision/transforms.html), [albumentations](https://albumentations.readthedocs.io/en/latest/api/augmentations.html), [augmentor](https://augmentor.readthedocs.io/en/master/), [imgaug](https://imgaug.readthedocs.io/en/latest/).\n",
    "* Попробуйте добавить шум.\n",
    "* Повернуть картинку + приблизить, чтобы убрать черные края.\n",
    "* Отразить её вертикально или горизонтально.\n",
    "* Сократить размер картинки, это позволит сократить параметры сети.\n",
    "* При аугментации всегда нужно помнить с какими данными мы работаем (разворачивание собаки на 180 градусов вам, наверняка, не поможет, потому что таких примеров, скорее всего, не будет в тестовой выборке).\n",
    "\n",
    "\n",
    "И главное: \n",
    "\n",
    "* Тестируйте только **одну идею за раз**.\n",
    "* Сохраняёте веса моделей (для каждого эксперимента, через N эпох, при достижении наилучшего качества на валидации), чтобы нечаянно не потерять результаты долгой работы.\n",
    "* Рисуйте кривые обучения (loss и метрику качества) для обучения и валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание на применение ваших знаний статистики:**\n",
    "\n",
    "Как всегда у всех горят сроки, заказчик просит скорее получить хорошую модель. Вы обучаете модель и видите по кривой обучения, что некоторый прирост в качестве еще есть. Только обучается она очень долго. Как понять, хватит ли уже проведенных итераций или нужно еще?\n",
    "Давайте проверим, значимо ли отличаются эти изменения. Проверьте стат значимость разницы в качестве на последней итерации и на одной из предыдущих итераций. Если результаты значимо отличаются, то имеет смысл дообучить модель.\n",
    "\n",
    "*P.S. Баллы даются за попытку реализации и за выводы, почему эта идея заработала/не заработала*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NTJXij7G7uQj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2RzRfhvHMip"
   },
   "source": [
    "Скачаем данные по ссылке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "E0uMuxuzNhZH",
    "outputId": "68db633f-1717-4f70-ab36-cabf03453551"
   },
   "outputs": [],
   "source": [
    "!wget -O data.tar.xz https://www.dropbox.com/s/w90m55pl7ylgiaf/data.tar.xz?dl=0\n",
    "!tar -xf data.tar.xz data\n",
    "!ls data/train | wc -l\n",
    "!find data/train -type f | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_EijZnFjnMc"
   },
   "source": [
    "В `train` датасете 51 художник (класс) и 6116 изображения картин (объектов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CBwt5duhjvoX"
   },
   "source": [
    "Посмотрим на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "PRJFzdSNjv_o",
    "outputId": "9588e563-3db1-4fd9-86c0-717958e880f5"
   },
   "outputs": [],
   "source": [
    "path_to_img = 'data/train/William_Turner/William_Turner_9.jpg'\n",
    "image = plt.imread(path_to_img)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pmpc_RdfpSQn"
   },
   "source": [
    "Разобьем `train` выборку на `train` и `val`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DGsi4AJ1kCbJ"
   },
   "outputs": [],
   "source": [
    "os.makedirs('data/val', exist_ok=True)\n",
    "\n",
    "TRAIN_FRAC = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "3glVY6H9pEEu",
    "outputId": "78991a36-a4b2-4045-fac7-0589dc6705f3"
   },
   "outputs": [],
   "source": [
    "# считываем названия директорий\n",
    "ARTIST_LIST = {i:name for i, name in enumerate(os.listdir('data/train/'))}\n",
    "IMAGES_DIR = 'data/train/'\n",
    "\n",
    "max_train_images = 0\n",
    "\n",
    "# создаем директорию с валидационной выборкой для каждого художника\n",
    "for artist in ARTIST_LIST.values():\n",
    "    os.makedirs(f'data/val/{artist}/', exist_ok=True)\n",
    "\n",
    "    # считываем выборку картин художника\n",
    "    artist_path = f'{IMAGES_DIR}/{artist}/'\n",
    "    images_filename = os.listdir(artist_path)\n",
    "    \n",
    "    # выделяем часть картин для валидации\n",
    "    num_train = int(len(images_filename) * TRAIN_FRAC)\n",
    "    max_train_images = max(max_train_images, num_train)\n",
    "    val_images = images_filename[num_train:]\n",
    "\n",
    "    print(f'{artist} | train images = {num_train} | val images = {len(val_images)}')\n",
    "    \n",
    "    # сохраняем валидационную выборку\n",
    "    for image_filename in val_images:\n",
    "        source = f'{IMAGES_DIR}/{artist}/{image_filename}'\n",
    "        destination = f'data/val/{artist}/{image_filename}'\n",
    "        shutil.copy(source, destination)\n",
    "        os.remove(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alWnsWAesj06"
   },
   "source": [
    "Данный датасет очень не сбалансирован по классам, возможные пути решения:\n",
    "* Random oversampling – включаем несколько копий объектов меньших классов, увеличивая их до размера большего класса\n",
    "* Random undersampling – не включаем часть объектов больших классов в обучающую выборку\n",
    "\n",
    "Предлагаем вам самим подумать как стоит бороться с дисбалансом классов и написать код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "t4oD-BX3gCaV",
    "outputId": "06ec6847-25fc-47b2-f7e0-eda4ca8b05a3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AAPA_OsQipP0"
   },
   "source": [
    "Убедимся еще раз, что в папке train и val все разложено по папкам-классам (авторам). Эта структура папок важна для использования классов PyTorch по работе с данными (`ImageFolder` и `DataLoader`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "G134scOxtJfH",
    "outputId": "69661794-29de-4500-ec9e-7a3644263383"
   },
   "outputs": [],
   "source": [
    "!ls data/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "Zy9jvWXLi2QQ",
    "outputId": "732cad1a-117b-4a51-b2c5-764bf99bd39e"
   },
   "outputs": [],
   "source": [
    "!ls data/val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hsj2NrwqUn6q"
   },
   "source": [
    "### Время для ваших экспериментов! \n",
    "\n",
    "Пока ваши нейросети будут обучаться можно начать заполнять отчет, который находится чуть ниже.\n",
    "\n",
    "Можете смело использовать код с семинара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRd8szRVPYeo"
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), \n",
    "                                     transform=transforms.ToTensor())\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), \n",
    "                                   transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2RQL4TTUzvO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jq1u4ymfVok1"
   },
   "source": [
    "Протестируйте своё решение:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vrMC6cXgVoBg"
   },
   "outputs": [],
   "source": [
    "# Используйте test_dataset только для финальной оценки качества\n",
    "test_dataset = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IE-pvhvsV_3p"
   },
   "outputs": [],
   "source": [
    "print(\"Итоговый результат:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 40:\n",
    "    print(\"Achievement unlocked: Transformer!\")\n",
    "elif test_accuracy * 100 > 35:\n",
    "    print(\"Achievement unlocked: LSTM!\")\n",
    "elif test_accuracy * 100 > 30:\n",
    "    print(\"Achievement unlocked: RNN!\")\n",
    "elif test_accuracy * 100 > 25:\n",
    "    print(\"Achievement unlocked: perceptron!\")\n",
    "else:\n",
    "    print(\"We need more \\\"layers\\\"! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1gqN4e3BYT6C"
   },
   "source": [
    "Обязательно заполните отчет. Опишите свои эксперименты: с чего вы начали, что попробовали улучшить и почему, заработало это или нет, какие вы сделали из этого выводы. Также обязательно опишите вашу лучшую архитектуру, методы обучения и интересные моменты.\n",
    "\n",
    "Отчет:\n",
    "....\n",
    "\n",
    "После ____ [минут, часов, дней] обучения, я получил следующие результаты:\n",
    "\n",
    "* accuracy on training: __\n",
    "* accuracy on validation: __\n",
    "* accuracy on test: __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kr6sE8f_7uY1"
   },
   "source": [
    "## Часть 2: Transfer Learning\n",
    "\n",
    "Попробуйте теперь использовать предобученную модель для классификации и сравните результаты.\n",
    "Сделав эту часть задания вы сможете получить 5 баллов.\n",
    "\n",
    "\n",
    "Вы можете пробовать любые предобученные архитектуры. Некоторые из них можно найти по ссылке [torchvision.models](https://pytorch.org/docs/stable/torchvision/models.html).\n",
    "\n",
    "Загрузите веса модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все предобученные модели можно разделить на две части:\n",
    "\n",
    "* Cверточная часть, которая работает как feature extractor.\n",
    "\n",
    "* Классификатор.\n",
    "\n",
    "Скорее всего вам потребуется заменить предобученный классификатор, чтобы использовать модель для работы с новым датасетом. Наиболее популярные подходы при замене классификатора:\n",
    "\n",
    "* Fully-connected слои.\n",
    "\n",
    "* Global average pooling. Подробнее можно прочитать в [статье](https://arxiv.org/pdf/1312.4400.pdf).\n",
    "\n",
    "* [Linear SVM](https://arxiv.org/pdf/1306.0239.pdf), если хочется чего-нибудь необычного.\n",
    "\n",
    "#### Несколько советов:\n",
    "\n",
    "* Так как входные данные разных моделей могут иметь разный размер, вам может потребоваться поменять исходный размер изображения. В этом могут помочь, например, `cv2.resize`, `skimage.resize` или `torch.transforms.Resize`.\n",
    "\n",
    "* Для дообучения слоев с предобученными весами можно использовать меньший learning rate, чем для обучения слоев со случайной инициализацией. Так как в самом начале обучения градиенты от случайно инициализированного классификатора могут слишком сильно изменить хорошие предобученные веса.\n",
    "\n",
    "#### Стратегии:\n",
    "\n",
    "* Использовать предобученную нейросеть как feature extractor, убрав последний FC слой. Обучить новый классификатор на полученном признаковом описании.\n",
    "\n",
    "* При обучении классификатора продолжить backpropagation на более глубокие слои нейросети (\"разморозить\" их). При этом возможно \"разморозить\" все слои или зафиксировать несколько начальных слоёв и не обучать их.\n",
    "\n",
    "* Вы можете совместить стратегии: сначала обучить классификатор, а потом постепенно размораживать слои и обучать их с меньшим learning rate-ом.\n",
    "\n",
    "Какую стратегию вы выбрали и почему?\n",
    "\n",
    "**Вывод:** ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните результаты предобученной модели и результаты из первой части. Сделайте вывод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
