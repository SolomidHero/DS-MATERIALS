{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наивный Байесовский классификатор."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке мы разберём один из самых простых методов классификации - наивный байесовский классификатор. Однако в некоторых задачах он работает даже лучше других, более сложных моделей. В любом случае, наивный байесовский классификатор содержит в себе важные теоретические идеи, поэтому с ним в любом случае полезно ознакомиться. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение при детекции спама.\n",
    "\n",
    "Данные для решения задачи детекции спама можно сделать следующим образом: взять набор размеченных текстовых сообщений, часть которых размечена как спам, а остальные - как не спам, зафиксировать словарь (самый простой вариант - взять все слова, встречающиеся в наборе текстовых сообщений) и преобразовать текстовые данные в целочисленные, посчитав для каждого слова из словаря, встречается ли оно в данном сообщении. А на этих данных уже можно обучить наивный байесовский классификатор.\n",
    "\n",
    "При реализации класса для наивного байесовского классификатора надо помнить один очень важный на практике момент: произведение вероятностей большого количества чисел может очень быстро сравняться с нулем при вычислении на компьютере, так как компьютеру может не хватить вычислительной точности. Поэтому при реализации стоит испльзовать логарифмы вероятностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим наивный байесовский классификатор к конкретному датасету https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Чтение данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "messages = []\n",
    "\n",
    "with open('SMSSpamCollection.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        cur_label, cur_message = line.split('\\t')\n",
    "        labels.append(cur_label)\n",
    "        messages.append(cur_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data label\n",
       "0  Go until jurong point, crazy.. Available only ...   ham\n",
       "1                    Ok lar... Joking wif u oni...\\n   ham\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
       "3  U dun say so early hor... U c already then say...   ham\n",
       "4  Nah I don't think he goes to usf, he lives aro...   ham"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame()\n",
    "raw_df['data'] = messages\n",
    "raw_df['label'] = labels\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете метки бывают 2 видов: \n",
    "* `ham` - означает, что сообщение - не спам, \n",
    "* `spam` - означает, что сообщение - спам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Предобработка данных.**\n",
    "\n",
    "Очевидно, что сразу в таком виде нельзя передавать данные наивному байесовскому классификатору. Их надо привести к численному виду. \n",
    "\n",
    "Столбец `label` привести к численному виду можно очень просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  label\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                    Ok lar... Joking wif u oni...\\n      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3  U dun say so early hor... U c already then say...      0\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['label'] = (raw_df['label'] == 'spam') * 1\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для преобразования текстовых сообщений воспользуемся `CountVectorizer`, работающий по принципу мешка слов (bag of words). Он имеет следующие гиперпараметры:\n",
    "\n",
    "* `max_df` -- максимальная доля сообщений, в которых может встречатся слово из словаря (такой параметр может быть полезен для борьбы со стоп-словами). То есть в словарь не включаются слишком частые слова.   \n",
    "* `min_df` -- минимальная доля сообщений, в которых может встречатся слово из словаря. То есть в словарь не включаются слишком редкие слова.\n",
    "* `max_features` -- максимамальное возможное число слов в словаре (берётся `max_features` наиболее частых слов).\n",
    "* `stop_words` -- можно просто взять и задать стоп-слова, которые не будут добавлены в словарь ни при каких обстоятельствах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=0.03)\n",
    "transformed_data = vectorizer.fit_transform(messages).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напечатаем весь мешок слов и их количество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "['all', 'am', 'and', 'are', 'at', 'be', 'but', 'call', 'can', 'come', 'day', 'do', 'for', 'free', 'from', 'get', 'go', 'good', 'got', 'gt', 'have', 'he', 'how', 'if', 'in', 'is', 'it', 'its', 'just', 'know', 'like', 'll', 'love', 'lt', 'me', 'my', 'no', 'not', 'now', 'of', 'ok', 'on', 'only', 'or', 'out', 'send', 'so', 'text', 'that', 'the', 'then', 'there', 'this', 'time', 'to', 'up', 'ur', 'want', 'was', 'we', 'what', 'when', 'will', 'with', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "print(len(vectorizer.get_feature_names()))\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на преобразованные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0 0 0 0\n",
      "  1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 2 1 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 0 0 2 1\n",
      "  0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 1 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(transformed_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Классификатор**\n",
    "\n",
    "В библиотеке `sklearn` имеются следующие реализации наивного байесовского классификатора:\n",
    "\n",
    "1) `BernoulliNB` - байесовский классификатор для данных, в которых все признаки являются бинарными.\n",
    "\n",
    "2) `MultinomialNB` - байесовский классификатор для данных, в которых все признаки являются дискретными.\n",
    "\n",
    "3) `GaussianNB` - байесовский классификатор для вещественных данных, каждый из признаков которых имеет нормальное распределение.\n",
    "\n",
    "Первые два метода имеют следующие гиперпараметры:\n",
    "* `alpha` -- коэффициент сглаживания Лапласа или Линдсона, при фиксированном значении `alpha` условные плотности будут записаны следующим образом:\n",
    "$$P(X_j=x_j|Y=y) = \\frac{\\#\\{ i : Y_i = y \\text{ & } X_{ij} = x_j\\} + \\alpha}{\\#\\{i: Y_i = y\\} + \\alpha d},$$\n",
    "    где $d$ -- количество признаков в датасете. При `alpha=0` сглаживания не происходит и получаются стандартные формулы для условных вероятностей; \n",
    "* `prior` -- арпиорные вероятности принадлежности каждому из классов. Кроме того, можно не только задавать априорное распределение руками, но и воспользоваться функцией `fit_prior`, которая восстановит априорное распределение по переданным в функцию данным.\n",
    "\n",
    "В нашей текущей задаче для признаков, описывающих количество вхождений каждого слова из словаря в сообщение, логично использовать `MultinomialNB`. Однако после мы сравним точность предсказаний `MultinomialNB` с точностью предсказаний `BernoulliNB` для бинарных признаков (каждый признак является индикатором того, присутствует ли данное слово из словаря в сообщении)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multinomial_nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обычно, разделим данные на обучающую выборку и на тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test \\\n",
    "    = train_test_split(transformed_data, raw_df['label'], \n",
    "                       random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель и смотрим качество на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9440459110473458\n",
      "f1 score: 0.7845303867403315\n"
     ]
    }
   ],
   "source": [
    "multinomial_nb.fit(X_train, y_train)\n",
    "predictions = multinomial_nb.predict(X_test)\n",
    "\n",
    "print('accuracy:', accuracy_score(predictions, y_test))\n",
    "print('f1 score:', f1_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат получился весьма неплохой.\n",
    "\n",
    "А теперь посмотрим, как с этой же задачей справится наивный байесовский классификатор на бинарных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X_train = (X_train > 0) * 1\n",
    "X_test = (X_test > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "bernoulli_nb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9497847919655668\n",
      "f1 score: 0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "bernoulli_nb.fit(X_train, y_train)\n",
    "predictions = bernoulli_nb.predict(X_test)\n",
    "\n",
    "print('accuracy:', accuracy_score(predictions, y_test))\n",
    "print('f1 score:', f1_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод.**\n",
    "\n",
    "Результат получился достаточно неожиданный. Наивный байесовский классификатор, обученный на бинаризованных данных показал более высокую точность классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Больший размер словаря**\n",
    "\n",
    "А теперь посмотрим, что будет, если мы возьмём другое количество слов для словаря.\n",
    "\n",
    "It's gonna be huge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5574, 8713)\n"
     ]
    }
   ],
   "source": [
    "huge_vectorizer = CountVectorizer()\n",
    "huge_data = huge_vectorizer.fit_transform(messages).toarray()\n",
    "print(huge_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    huge_data, raw_df['label'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9849354375896701\n",
      "f1 score: 0.9454545454545454\n"
     ]
    }
   ],
   "source": [
    "multinomial_nb.fit(X_train, y_train)\n",
    "predictions = multinomial_nb.predict(X_test)\n",
    "\n",
    "print('accuracy:', accuracy_score(predictions, y_test))\n",
    "print('f1 score:', f1_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9806312769010043\n",
      "f1 score: 0.9247910863509748\n"
     ]
    }
   ],
   "source": [
    "bernoulli_nb.fit(X_train, y_train)\n",
    "predictions = bernoulli_nb.predict(X_test)\n",
    "\n",
    "print('accuracy:', accuracy_score(predictions, y_test))\n",
    "print('f1 score:', f1_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод.**\n",
    "\n",
    "От увеличения количества рассматриваемых слов в данном случае точность предсказаний возрасла как для наивного байесовского классификатора над категориальными признаками, так и для классификатора над бинарными признаками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусная часть\n",
    "\n",
    "1. Рассмотрите различные способы построения словаря для классификации, например, установив некоторые параметры класса `CountVectorizer`.\n",
    "    \n",
    " \n",
    "2. Попытайтесь улучшить точность классификации (на тестовой выборке) наивного байесовского классификатор за счёт изменения гиперпаметров классификатора. \n",
    "\n",
    " \n",
    "3. Решите задачу детекции спама при помощи некоторого другого известного классификатора: логистической регрессии, kNN и сравните точность предсказаний с наивным байесовским классификатором."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
